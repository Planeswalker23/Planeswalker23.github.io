---
layout: post
title: HashMap 底层实现、加载因子、容量值及死循环
categories: [Java]
description: HashMap 底层实现、加载因子、容量值及死循环
keywords: HashMap, Java
---

## HashMap 简介
`HashMap`是一个基于哈希表实现的无序的`key-value`容器，它键和值允许设置为 `null`，同时它是线程不安全的。

## HashMap 底层实现
- 在`jdk 1.7`中`HashMap`是以数组+链表的实现的
- 在`jdk1.8`开始引入红黑树，`HashMap`底层变成了数组+链表+红黑树实现

### 红黑树简介
红黑树是一种特殊的平衡二叉树，它有如下的特征：
- 节点是红色或黑色
- 根节点是黑色的
- 所有叶子都是黑色。（叶子是`NULL`节点）
- 每个红色节点的两个子节点都是黑色的（从每个叶子到根的所有路径上不能有两个连续的红色节点）
- 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

所以红黑树的时间复杂度为: `O(lgn)`。

![2020-04-12-1.png](https://planeswalker23.github.io/images/posts/2020-04-12-1.png)

### jdk1.8：数组+链表+红黑树
`HashMap`的底层首先是一个数组，元素存放的数组索引值就是由该元素的哈希值（`key-value`中`key`的哈希值）确定的，这就可能产生一种特殊情况——不同的`key`哈希值相同。

在这样的情况下，于是引入链表，如果`key`的哈希值相同，在数组的该索引中存放一个链表，这个链表就包含了所有`key`的哈希值相同的`value`值，这就解决了哈希冲突的问题。

但是如果发生大量哈希值相同的特殊情况，导致链表很长，就会严重影响`HashMap`的性能，因为链表的查询效率需要遍历所有节点。于是在`jdk1.8`引入了红黑树，当链表的长度大于8，且`HashMap`的容量大于64的时候，就会将链表转化为红黑树。

```java
// jdk1.8
// HashMap#putVal

// binCount 是该链表的长度计数器，当链表长度大于等于8时，执行树化方法
// TREEIFY_THRESHOLD = 8
if (binCount >= TREEIFY_THRESHOLD - 1)
    treeifyBin(tab, hash);

// HashMap#treeifyBin    
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    // MIN_TREEIFY_CAPACITY=64
    // 若 HashMap 的大小小于64，仅扩容，不树化
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
```

## 加载因子为什么是0.75
所谓的加载因子，也叫扩容因子或者负载因子，它是用来进行扩容判断的。

假设加载因子是0.5，`HashMap`初始化容量是16，当`HashMap`中有`16 * 0.5=8`个元素时，`HashMap`就会进行扩容操作。

而`HashMap`中加载因子为0.75，是考虑到了性能和容量的平衡。

由加载因子的定义，可以知道它的取值范围是(0, 1]。

- 如果加载因子过小，那么扩容门槛低，扩容频繁，这虽然能使元素存储得更稀疏，有效避免了哈希冲突发生，同时操作性能较高，但是会占用更多的空间。

- 如果加载因子过大，那么扩容门槛高，扩容不频繁，虽然占用的空间降低了，但是这会导致元素存储密集，发生哈希冲突的概率大大提高，从而导致存储元素的数据结构更加复杂（用于解决哈希冲突），最终导致操作性能降低。

- 还有一个因素是为了提升扩容效率。因为`HashMap`的容量（`size`属性，构造函数中的`initialCapacity`变量）有一个要求：它一定是2的幂。所以加载因子选择了0.75就可以保证它与容量的乘积为整数。

```java
// 构造函数
public HashMap(int initialCapacity, float loadFactor) {
    // ……
    this.loadFactor = loadFactor;// 加载因子
    this.threshold = tableSizeFor(initialCapacity);
}

/**
 * Returns a power of two size for the given target capacity.返回2的幂
 * MAXIMUM_CAPACITY = 1 << 30
 */
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

## HashMap 的容量为什么是2的 n 次幂
> `HashMap`的默认初始容量是16，而每次扩容是扩容为原来的2倍。这里的16和2倍就保证了`HashMap`的容量是2的n次幂，那么这样设计的原因是什么呢？

### 原因一：与运算高效
与运算`&`，基于二进制数值，同时为1结果为1，否则就是0。如1&1=1,1&0=0,0&0=0。使用与运算的原因就是对于计算机来说，与运算十分高效。

### 原因二：有利于元素充分散列，减少 Hash 碰撞
在给`HashMap`添加元素的`putVal`函数中，有这样一段代码：

```java
// n为容量，hash为该元素的hash值
if ((p = tab[i = (n - 1) & hash]) == null)
    tab[i] = newNode(hash, key, value, null);
```

它会在添加元素时，通过`i = (n - 1) & hash`计算该元素在`HashMap`中的位置。

当 HashMap 的容量为 2 的 n 次幂时，他的二进制值是100000……（n个0），所以n-1的值就是011111……（n个1），这样的话`(n - 1) & hash`的值才能够充分散列。

举个例子，假设容量为16，现在有哈希值为1111，1110，1011，1001四种将被添加，它们与n-1(15的二进制=01111)的哈希值分别为1111、1110、1110、1011，都不相同。

而假设容量不为2的n次幂，假设为10，那么它与上述四个哈希值进行与运算的结果分别是：0101、0100、0001、0001。

可以看到后两个值发生了碰撞，从中可以看出，非2的n次幂会加大哈希碰撞的概率。所以 HashMap 的容量设置为2的n次幂有利于元素的充分散列。

<a href="https://blog.csdn.net/apeopl/article/details/88935422" target="_blank">参考：HashMap初始容量为什么是2的n次幂及扩容为什么是2倍的形式</a>

## HashMap 是如何导致死循环的
`HashMap`会导致死循环是在`jdk1.7`中，由于扩容时的操作是使用头插法，在多线程的环境下可能产生循环链表，由此导致了死循环。在`jdk1.8`中改为使用尾插法，避免了该死循环的情况。

在网上找到了比较详细的解释分析博客与视频：

<a href="https://blog.csdn.net/maohoo/article/details/81531925" target="_blank">老生常谈，HashMap的死循环【基于JDK1.7】</a>

<a href="https://www.bilibili.com/video/BV1y441187jR?t=3436" target="_blank">jdk1.7及1.8HashMap,ConcurrentHashMap实现原理,自己使用,侵删</a>